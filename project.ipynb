{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pands Project\n",
    "\n",
    "This Jupyter Notebook will provide a brief description of the outputs of my analysis.py code.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary.txt\n",
    "\n",
    "This txt file outlines some key insights into the varibales of the Iris dataset.\n",
    "\n",
    "- It provides a sample of the Iris dataset by printing the first five lines. This shows how the dataset is structured and gives some examples of the attributes of the first five flowers (this helps to add some context for what the variables are describing).\n",
    "\n",
    "- Next, it shows the types of data each of these variables are. These are either float64 (floating point numbers/numers with decimal points, stored using 64 bits) or object (in this case this is limited to the class variable which is of type string, it is the only categorical variable of the dataset). \n",
    "\n",
    "- It then lists the unique values of the class variable (these are the different Iris species).\n",
    "\n",
    "- Lastly, it provides a summary of the numerical variables (these are the variables listed in the types summary that show as float64). The output is a table that shows counts, means (sum of the numbers divided by amount of values), standard deviations (how varied the numbers are relative to the mean), minimum and maximum values (in this case, the longest and widest petal and sepals as well as the smallest) and the points at which 25, 50 and 75 percent of values are below the given value.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### histograms_of_iris_variables.png\n",
    "\n",
    "- This figure plots 4 subplots, these are the histograms of the four numerical variables from the Iris dataset. The Iris species are distinguished by colour and there is a slight transparecy on the bars to allow the viewer to see through the colours (to clearly compare the different species). For all of the subplots, the axes are labelled with frequency on the y axis and the length/width on the x axis.\n",
    "\n",
    "- For the most part these histograms adhere to normal, or Guassian, distribution (they appear in a 'bell curve' shape). In some cases the 'peaks' or points where the variable has it's mode (the highest frequency of values) are close together for the various species (such as sepal width) or far apart, seperated by troughs (for example, the petal width).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairplots.png\n",
    "\n",
    "- Rather than producing seval scatterplots I decided to use seaborn to make one pairplot. This pairplot shows the relationship between the pairs of variables in the Iris dataset. For instance, the first plot on the second row visualises the relationship between sepal width and sepal length. Again, the species are distinguished by colour- it's evident that the species are morpholigically different by assessing how te clusters of coloured dots sit at different points to one another- indicating that one species is typically bigger than another,etc. In the plot I mentioned previosuly (sepal width vs sepal lenth) we can see that, on average, the *Iris Setosa* tends to grow wider sepals compared to the other species, however- both the *Iris Versicolor* and the *Iris Virginica* tend to have longer sepals.\n",
    "\n",
    "- As histograms have already been created earlier in my analysis, I decided to add kernal density estimates to the diagonal of this figure.These are essentially 'smoothed out' estimations of the relationship between the variables.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation_coefficients.txt\n",
    "\n",
    "- This is my additional analysis which displays a table showing the Pearson's correlation coefficient of each pair of variables. The Pearson correlation coefficient is a numerical measure of linear correlation: as two variables become more strongly associated they will come closer to a Pearson correlation coefficient of +1 (positive relationship) or -1 (negative relationship). If the Pearsons correlation coefficient is exactly +1, then all the values would be on our line of best fit.\n",
    "\n",
    "- In the Iris dataset there are pairs of variables which are positively related to one another (such as petal length and sepal length- with a strong correlation coefficient of 0.87) and those that have negative relationships (such as petal length and sepal width, -0.41). Wherever there is a 1.0 on the table that shows the relationship between one variable and itself (ie. as would be the case with any variable, it has a perfect positive relationship with itself).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "These are just some of the many coding, scripting, data analytics and statistical techniques we can apply to the Iris dataset. The techniques demonstrated in this project are foundational and can be used in a multitude of different ways to gain insights and understandings into the Iris dataset.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
